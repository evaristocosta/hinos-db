{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55bc14c",
   "metadata": {},
   "source": [
    "# RAG da Colet√¢nea\n",
    "\n",
    "Elabora√ß√£o de um sistema de LLM+RAG (Retrieval-Augmented Generation) para o database da Colet√¢nea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b167ac",
   "metadata": {},
   "source": [
    "## Exemplo m√≠nimo de RAG com LangChain + Ollama\n",
    "\n",
    "Fluxo: instalar depend√™ncias, localizar `database.db`, carregar hinos, gerar embedding/chroma simples e testar uma consulta.\n",
    "\n",
    "> Certifique-se de que o servidor do Ollama est√° rodando e que o modelo de embedding/LLM (ex.: `nomic-embed-text`, `llama3`) est√° baixado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31ae28",
   "metadata": {},
   "source": [
    "## Checklist r√°pido antes de rodar\n",
    "- Suba o servidor do Ollama e garanta que os modelos `nomic-embed-text` e `gemma3:4b` est√£o baixados.\n",
    "- Confirme o caminho do `database.db` (as rotas j√° tentam achar na raiz do repo).\n",
    "- Instale as depend√™ncias na c√©lula seguinte (comente/descomente o `%pip`).\n",
    "- Rode as c√©lulas na ordem; a primeira execu√ß√£o cria os caches/chroma em `shared/rag/` e reaproveita nas pr√≥ximas.\n",
    "- Ajuste `max_rows` ou par√¢metros de chunking/indexa√ß√£o se quiser limitar dados para testes r√°pidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando libs necess√°rias\n",
    "# %pip install -q langchain langchain-community langchain-ollama langchain-chroma chromadb sqlite-utils pydantic rank-bm25 difflib python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85563c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "# Localiza o database.db a partir deste notebook\n",
    "candidates = [\n",
    "    Path.cwd() / \"database\" / \"database.db\",\n",
    "    Path.cwd().parent / \"database\" / \"database.db\",\n",
    "    Path.cwd().parent.parent / \"database\" / \"database.db\",\n",
    "]\n",
    "db_path = next((p for p in candidates if p.exists()), None)\n",
    "if not db_path:\n",
    "    raise FileNotFoundError(\"database.db n√£o encontrado; ajuste o caminho na lista de candidates.\")\n",
    "\n",
    "print(f\"Usando DB: {db_path}\")\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = [r[0] for r in cur.fetchall()]\n",
    "    cur.execute(\"SELECT count(*) FROM hino\")\n",
    "    total_hinos = cur.fetchone()[0]\n",
    "\n",
    "print(f\"Tabelas: {tables}\")\n",
    "print(f\"Total de hinos: {total_hinos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430ea0f",
   "metadata": {},
   "source": [
    "## Indexa√ß√£o: chunks e vectorstore\n",
    "Esta etapa cria (ou reaproveita) os chunks dos hinos e o vectorstore Chroma.\n",
    "- Usa cache em `shared/rag/chunks_cache.pkl` para evitar re-splitting.\n",
    "- Persiste o Chroma em `shared/rag/vectorstore/`.\n",
    "- Altere `max_rows`, `chunk_size` ou `chunk_overlap` no c√≥digo seguinte se precisar de execu√ß√µes mais leves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Configura√ß√£o de embedding\n",
    "OLLAMA_EMBED_MODEL = \"nomic-embed-text\"\n",
    "embeddings = OllamaEmbeddings(model=OLLAMA_EMBED_MODEL)\n",
    "\n",
    "# Diret√≥rios de cache\n",
    "vector_dir = Path.cwd().parent / \"shared\" / \"rag\" / \"vectorstore\"\n",
    "chunks_cache = Path.cwd().parent / \"shared\" / \"rag\" / \"chunks_cache.pkl\"\n",
    "\n",
    "# ===== CARREGAR CHUNKS DO CACHE PRIMEIRO =====\n",
    "if chunks_cache.exists():\n",
    "    print(f\"‚úì Carregando chunks do cache: {chunks_cache}\")\n",
    "    with open(chunks_cache, \"rb\") as f:\n",
    "        chunks = pickle.load(f)\n",
    "    print(f\"‚úì {len(chunks)} chunks carregados do cache\")\n",
    "else:\n",
    "    # Se n√£o tem cache, carrega hinos e cria chunks\n",
    "    print(f\"‚ö† Cache de chunks n√£o encontrado. Criando do zero...\")\n",
    "\n",
    "    # Carrega hinos do banco\n",
    "    max_rows = total_hinos\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT id, nome, numero, texto_limpo AS texto, \n",
    "                   categoria_id, coletanea_id\n",
    "            FROM hino\n",
    "            WHERE texto_limpo IS NOT NULL\n",
    "            ORDER BY id\n",
    "            LIMIT ?\n",
    "            \"\"\",\n",
    "            (max_rows,),\n",
    "        )\n",
    "        rows = cur.fetchall()\n",
    "\n",
    "    print(f\"‚úì {len(rows)} hinos carregados do DB\")\n",
    "\n",
    "    # Cria documentos\n",
    "    docs = []\n",
    "    for hid, nome, numero, texto, categoria_id, coletanea_id in tqdm(rows, desc=\"Criando documentos\"):\n",
    "        if not texto:\n",
    "            continue\n",
    "        content = f\"{nome or ''} ({numero or ''})\\n\\n{texto.strip()}\"\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"hino_id\": hid,\n",
    "                    \"nome\": nome,\n",
    "                    \"numero\": numero,\n",
    "                    \"categoria_id\": categoria_id,\n",
    "                    \"coletanea_id\": coletanea_id,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Cria chunks\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)\n",
    "    chunks = []\n",
    "    for doc in tqdm(docs, desc=\"Criando chunks\"):\n",
    "        chunks.extend(splitter.split_documents([doc]))\n",
    "    print(f\"‚úì {len(chunks)} chunks criados de {len(docs)} hinos\")\n",
    "\n",
    "    # Salva chunks no cache\n",
    "    print(f\"üíæ Salvando chunks em: {chunks_cache}\")\n",
    "    with open(chunks_cache, \"wb\") as f:\n",
    "        pickle.dump(chunks, f)\n",
    "    print(f\"‚úì Chunks salvos com sucesso!\")\n",
    "\n",
    "# ===== CARREGAR/CRIAR VECTORSTORE =====\n",
    "if vector_dir.exists() and (vector_dir / \"chroma.sqlite3\").exists():\n",
    "    print(f\"‚úì Carregando vectorstore de: {vector_dir}\")\n",
    "    vectorstore = Chroma(embedding_function=embeddings, persist_directory=str(vector_dir))\n",
    "    print(f\"‚úì Vectorstore carregado com sucesso!\")\n",
    "else:\n",
    "    print(f\"‚ö† Vectorstore n√£o encontrado. Criando do zero...\")\n",
    "    print(f\"üî® Criando vectorstore em: {vector_dir}\")\n",
    "    vectorstore = Chroma(embedding_function=embeddings, persist_directory=str(vector_dir))\n",
    "    batch_size = 64\n",
    "    for i in tqdm(range(0, len(chunks), batch_size), desc=\"Indexando\"):\n",
    "        batch = chunks[i : i + batch_size]\n",
    "        vectorstore.add_documents(batch)\n",
    "    print(f\"‚úì Vectorstore criado e salvo!\")\n",
    "\n",
    "print(f\"\\n‚úÖ Setup completo! Vectorstore ({len(chunks)} chunks) pronto para uso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c4c2e",
   "metadata": {},
   "source": [
    "## Configura√ß√£o de Filtros e Metadados\n",
    "\n",
    "Carrega categorias e colet√¢neas dispon√≠veis no banco para uso em filtros din√¢micos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae541d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca categorias e colet√¢neas dispon√≠veis para filtros\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT id, descricao FROM categoria\")\n",
    "    categorias = {row[1].lower(): row[0] for row in cur.fetchall()}\n",
    "    \n",
    "    cur.execute(\"SELECT id, nome FROM coletanea\")\n",
    "    coletaneas = {row[1].lower(): row[0] for row in cur.fetchall()}\n",
    "\n",
    "print(f\"‚úì Categorias: {list(categorias.keys())}\")\n",
    "print(f\"‚úì Colet√¢neas: {list(coletaneas.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de149f",
   "metadata": {},
   "source": [
    "## Configura√ß√£o de Retrievers e LLM\n",
    "\n",
    "Configura o LLM, retrievers (vetorial MMR + BM25 h√≠brido) e prompts base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "import re\n",
    "\n",
    "# LLM principal\n",
    "llm = OllamaLLM(model=\"gemma3:4b\", temperature=0.3)\n",
    "\n",
    "# Stopwords personalizadas\n",
    "stopwords_path = Path.cwd().parent / \"etl-similarity\" / \"assets\" / \"stopwords-br.txt\"\n",
    "with open(stopwords_path, encoding=\"utf-8\") as f:\n",
    "    STOPWORDS = {\n",
    "        line.strip().strip('\"')\n",
    "        for line in f\n",
    "        if line.strip() and not line.startswith(\"#\")\n",
    "    }\n",
    "\n",
    "# Tokenizador para BM25\n",
    "WORD_RE = re.compile(r\"\\w+\")\n",
    "def bm25_tokenizer(text: str):\n",
    "    tokens = WORD_RE.findall(text.lower())\n",
    "    return [t for t in tokens if t not in STOPWORDS]\n",
    "\n",
    "# Retrievers\n",
    "vector_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 8, \"fetch_k\": 20}\n",
    ")\n",
    "\n",
    "# BM25 (apenas se chunks dispon√≠veis)\n",
    "if chunks:\n",
    "    bm25_retriever = BM25Retriever.from_documents(chunks, preprocess_func=bm25_tokenizer)\n",
    "    bm25_retriever.k = 8\n",
    "    print(\"‚úì BM25 retriever configurado\")\n",
    "else:\n",
    "    bm25_retriever = None\n",
    "    print(\"‚ö† BM25 n√£o dispon√≠vel (chunks n√£o carregados)\")\n",
    "\n",
    "# Prompts base\n",
    "rewrite_system_str = \"\"\"\n",
    "Reescreva a consulta do usu√°rio para busca em hinos, expandindo com sin√¥nimos e termos relacionados, \n",
    "mantendo inten√ß√£o e concis√£o. Mantenha as palavras que estiverem entre aspas. \n",
    "N√£o adicione explica√ß√µes sobre as altera√ß√µes na consulta.\n",
    "\"\"\"\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", rewrite_system_str),\n",
    "    (\"user\", \"Consulta: {question}\"),\n",
    "])\n",
    "rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "def format_docs(docs):\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        parts.append(f\"[{d.metadata.get('numero') or 'N/A'}] {d.metadata.get('nome')}\\n{d.page_content}\")\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "answer_system_str = \"\"\"\n",
    "Voc√™ √© um assistente que responde apenas com base na colet√¢nea de hinos. \n",
    "√â prefer√≠vel retornar mais de uma op√ß√£o, pelo menos tr√™s, quando dispon√≠vel.\n",
    "Explique os motivos de selecionar tais hinos. \n",
    "Cite n√∫meros (se houver) e t√≠tulos.\n",
    "Se n√£o souber, diga que n√£o est√° na base.\n",
    "\"\"\"\n",
    "\n",
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", answer_system_str),\n",
    "    (\"user\", \"Pergunta original: {question}\\n\\nConsulta reescrita: {rewritten}\\n\\nContexto:\\n{context}\\n\\nResposta:\"),\n",
    "])\n",
    "\n",
    "print(\"‚úì LLM e retrievers configurados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34bdfda",
   "metadata": {},
   "source": [
    "## Sistema de Busca com Filtros Din√¢micos\n",
    "\n",
    "Implementa busca h√≠brida (vetorial + BM25) com extra√ß√£o autom√°tica de filtros de categoria/colet√¢nea via LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import unicodedata\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# ==== Utilidades para refer√™ncias b√≠blicas ====\n",
    "def _normalize_text(text: str) -> str:\n",
    "    nfkd = unicodedata.normalize(\"NFKD\", text)\n",
    "    return \"\".join(c for c in nfkd if not unicodedata.combining(c)).lower().strip()\n",
    "\n",
    "BIBLE_BOOK_MAP: Dict[str, str] = {\n",
    "    \"genesis\": \"Genesis\",\n",
    "    \"exodo\": \"Exodus\",\n",
    "    \"levitico\": \"Leviticus\",\n",
    "    \"numeros\": \"Numbers\",\n",
    "    \"deuteronomio\": \"Deuteronomy\",\n",
    "    \"josue\": \"Joshua\",\n",
    "    \"juizes\": \"Judges\",\n",
    "    \"rute\": \"Ruth\",\n",
    "    \"1samuel\": \"1 Samuel\",\n",
    "    \"2samuel\": \"2 Samuel\",\n",
    "    \"1reis\": \"1 Kings\",\n",
    "    \"2reis\": \"2 Kings\",\n",
    "    \"1cronicas\": \"1 Chronicles\",\n",
    "    \"2cronicas\": \"2 Chronicles\",\n",
    "    \"esdras\": \"Ezra\",\n",
    "    \"neemias\": \"Nehemiah\",\n",
    "    \"ester\": \"Esther\",\n",
    "    \"jo\": \"Job\",\n",
    "    \"salmos\": \"Psalms\",\n",
    "    \"proverbios\": \"Proverbs\",\n",
    "    \"eclesiastes\": \"Ecclesiastes\",\n",
    "    \"cantico\": \"Song of Solomon\",\n",
    "    \"canticos\": \"Song of Solomon\",\n",
    "    \"cantares\": \"Song of Solomon\",\n",
    "    \"isaias\": \"Isaiah\",\n",
    "    \"jeremias\": \"Jeremiah\",\n",
    "    \"lamentacoes\": \"Lamentations\",\n",
    "    \"ezequiel\": \"Ezekiel\",\n",
    "    \"daniel\": \"Daniel\",\n",
    "    \"oseias\": \"Hosea\",\n",
    "    \"joel\": \"Joel\",\n",
    "    \"amos\": \"Amos\",\n",
    "    \"obadias\": \"Obadiah\",\n",
    "    \"jonas\": \"Jonah\",\n",
    "    \"miqueias\": \"Micah\",\n",
    "    \"naum\": \"Nahum\",\n",
    "    \"habacuque\": \"Habakkuk\",\n",
    "    \"sofonias\": \"Zephaniah\",\n",
    "    \"ageu\": \"Haggai\",\n",
    "    \"zacarias\": \"Zechariah\",\n",
    "    \"malaquias\": \"Malachi\",\n",
    "    \"mateus\": \"Matthew\",\n",
    "    \"marcos\": \"Mark\",\n",
    "    \"lucas\": \"Luke\",\n",
    "    \"joao\": \"John\",\n",
    "    \"atos\": \"Acts\",\n",
    "    \"romanos\": \"Romans\",\n",
    "    \"1corintios\": \"1 Corinthians\",\n",
    "    \"2corintios\": \"2 Corinthians\",\n",
    "    \"galatas\": \"Galatians\",\n",
    "    \"efesios\": \"Ephesians\",\n",
    "    \"filipenses\": \"Philippians\",\n",
    "    \"colossenses\": \"Colossians\",\n",
    "    \"1tessalonicenses\": \"1 Thessalonians\",\n",
    "    \"2tessalonicenses\": \"2 Thessalonians\",\n",
    "    \"1timoteo\": \"1 Timothy\",\n",
    "    \"2timoteo\": \"2 Timothy\",\n",
    "    \"tito\": \"Titus\",\n",
    "    \"filemom\": \"Philemon\",\n",
    "    \"hebreus\": \"Hebrews\",\n",
    "    \"tiago\": \"James\",\n",
    "    \"1pedro\": \"1 Peter\",\n",
    "    \"2pedro\": \"2 Peter\",\n",
    "    \"1joao\": \"1 John\",\n",
    "    \"2joao\": \"2 John\",\n",
    "    \"3joao\": \"3 John\",\n",
    "    \"judas\": \"Jude\",\n",
    "    \"apocalipse\": \"Revelation\",\n",
    "}\n",
    "\n",
    "REF_RE = re.compile(\n",
    "    r\"(?i)([1-3]?\\s?[A-Za-z√Ä-√ø√ß√£√µ√¢√™√¥√°√©√≠√≥√∫]+(?:\\s+dos\\s+canticos|\\s+de\\s+canticos|\\s+dos\\s+reis|\\s+cronicas|\\s+corintios|\\s+tessalonicenses|\\s+pedro|\\s+joao)*)\\s+(\\d{1,3})(?:[:\\.](\\d{1,3})(?:-(\\d{1,3}))?)?\"\n",
    ")\n",
    "\n",
    "def _normalize_book_key(book: str) -> str:\n",
    "    return _normalize_text(book).replace(\" \", \"\")\n",
    "\n",
    "\n",
    "def extract_bible_refs(text: str) -> List[dict]:\n",
    "    refs: List[dict] = []\n",
    "    seen = set()\n",
    "    for match in REF_RE.finditer(text or \"\"):\n",
    "        book_raw = match.group(1)\n",
    "        chapter = match.group(2)\n",
    "        verse_start = match.group(3)\n",
    "        verse_end = match.group(4)\n",
    "\n",
    "        key = _normalize_book_key(book_raw)\n",
    "        if key not in BIBLE_BOOK_MAP:\n",
    "            continue\n",
    "\n",
    "        api_book = BIBLE_BOOK_MAP[key]\n",
    "\n",
    "        # Se n√£o h√° verso, √© um cap√≠tulo inteiro\n",
    "        if verse_start is None:\n",
    "            label = f\"{book_raw.strip()} {chapter}\"\n",
    "            api_ref = f\"{api_book} {chapter}\"\n",
    "        else:\n",
    "            # Com verso (pode ter range)\n",
    "            label = f\"{book_raw.strip()} {chapter}:{verse_start}{('-' + verse_end) if verse_end else ''}\"\n",
    "            api_ref = f\"{api_book} {chapter}:{verse_start}{('-' + verse_end) if verse_end else ''}\"\n",
    "\n",
    "        if api_ref in seen:\n",
    "            continue\n",
    "        seen.add(api_ref)\n",
    "        refs.append(\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"api_ref\": api_ref,\n",
    "                \"type\": \"chapter\" if verse_start is None else \"verse\",\n",
    "            }\n",
    "        )\n",
    "    return refs\n",
    "\n",
    "\n",
    "def fetch_bible_verses(\n",
    "    refs: List[dict], translation: str = \"almeida\", max_chars: int = 1200\n",
    ") -> str:\n",
    "    verses = []\n",
    "    total_len = 0\n",
    "    for ref in refs:\n",
    "        try:\n",
    "            resp = requests.get(\n",
    "                f\"https://bible-api.com/{requests.utils.quote(ref['api_ref'])}\",\n",
    "                params={\"translation\": translation},\n",
    "                timeout=8,\n",
    "            )\n",
    "            if resp.status_code != 200:\n",
    "                continue\n",
    "            data = resp.json()\n",
    "            text_parts = [v.get(\"text\", \"\").strip() for v in data.get(\"verses\", [])]\n",
    "            verse_text = \" \".join([t for t in text_parts if t])\n",
    "            if not verse_text:\n",
    "                continue\n",
    "\n",
    "            # Para cap√≠tulos inteiros, trunca se for muito longo\n",
    "            is_chapter = ref.get(\"type\") == \"chapter\"\n",
    "            if is_chapter and len(verse_text) > 800:\n",
    "                verse_text = verse_text[:800] + \"...\"\n",
    "\n",
    "            snippet = f\"{ref['label']} ‚Äî {verse_text}\"\n",
    "            verses.append(snippet)\n",
    "            total_len += len(snippet)\n",
    "            if total_len >= max_chars:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    return \"\\n\".join(verses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc46a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "import unicodedata\n",
    "\n",
    "# ===== EXTRA√á√ÉO DETERMIN√çSTICA DE FILTROS =====\n",
    "\n",
    "def _normalize_for_matching(text: str) -> str:\n",
    "    \"\"\"Normaliza texto para matching: remove acentos, converte a min√∫sculas, remove espa√ßos extras.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Remove acentos\n",
    "    nfkd = unicodedata.normalize(\"NFKD\", text)\n",
    "    text_no_accents = \"\".join(c for c in nfkd if not unicodedata.combining(c))\n",
    "    # Min√∫sculas e espa√ßo √∫nico\n",
    "    return \" \".join(text_no_accents.lower().split())\n",
    "\n",
    "\n",
    "def _find_matches_in_text(query: str, candidates: list) -> list:\n",
    "    \"\"\"\n",
    "    Busca candidatos dentro da query usando estrat√©gia h√≠brida:\n",
    "    1. Substring match exato (normalizado) - score 1.0\n",
    "    2. Partial token match - score baseado em tokens comuns\n",
    "    3. Fuzzy matching (thefuzz) como fallback\n",
    "\n",
    "    Retorna lista de (candidate, score) ordenada por score.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    query_norm = _normalize_for_matching(query)\n",
    "    query_tokens = set(query_norm.split())\n",
    "\n",
    "    for candidate in candidates:\n",
    "        candidate_norm = _normalize_for_matching(candidate)\n",
    "\n",
    "        # Estrat√©gia 1: Substring match direto (melhor caso)\n",
    "        if candidate_norm in query_norm:\n",
    "            matches.append((candidate, 1.0))\n",
    "            continue\n",
    "\n",
    "        # Estrat√©gia 2: Match por tokens (bom para varia√ß√µes de ordem)\n",
    "        candidate_tokens = set(candidate_norm.split())\n",
    "        if len(candidate_tokens) == 0:\n",
    "            continue\n",
    "\n",
    "        # Calcula overlap de tokens\n",
    "        common_tokens = query_tokens & candidate_tokens\n",
    "        token_ratio = len(common_tokens) / len(candidate_tokens)\n",
    "\n",
    "        # Se a maioria dos tokens da categoria est√° na query, considera match\n",
    "        if token_ratio >= 0.7:\n",
    "            matches.append((candidate, token_ratio))\n",
    "            continue\n",
    "\n",
    "        # Estrat√©gia 3: Fuzzy matching como fallback (para typos)\n",
    "        # Usa partial_ratio que √© ideal para encontrar substring fuzzy\n",
    "        if len(candidate_norm.split()) <= 4:\n",
    "            ratio = fuzz.partial_ratio(candidate_norm, query_norm) / 100.0\n",
    "            # Threshold mais alto para fuzzy, pois j√° falhou nos outros m√©todos\n",
    "            if ratio >= 0.6:\n",
    "                matches.append((candidate, ratio * 0.8))  # Penaliza fuzzy match\n",
    "\n",
    "    # Ordena por score (descendente)\n",
    "    return sorted(matches, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def _extract_filters_deterministic(question: str, categorias_dict: dict, coletaneas_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extrai filtros de forma determin√≠stica sem usar LLM.\n",
    "    \n",
    "    Estrat√©gia:\n",
    "    1. Busca categorias/colet√¢neas contidas na query (substring + token matching)\n",
    "    2. Remove as refer√™ncias encontradas da query\n",
    "    3. Retorna filtros e query limpa\n",
    "    \"\"\"\n",
    "    question_lower = question.lower()\n",
    "    found_categorias = []\n",
    "    found_coletaneas = []\n",
    "    \n",
    "    # Extrai poss√≠veis categorias\n",
    "    categoria_names = list(categorias_dict.keys())\n",
    "    cat_matches = _find_matches_in_text(question_lower, categoria_names)\n",
    "    \n",
    "    # Aceita matches com score >= 0.7 (alta confian√ßa)\n",
    "    for cat_name, score in cat_matches:\n",
    "        if score >= 0.7:\n",
    "            found_categorias.append(cat_name)\n",
    "            # Remove a refer√™ncia da pergunta (para limpeza)\n",
    "            question_lower = question_lower.replace(cat_name.lower(), \" \")\n",
    "    \n",
    "    # Extrai poss√≠veis colet√¢neas\n",
    "    coletanea_names = list(coletaneas_dict.keys())\n",
    "    col_matches = _find_matches_in_text(question_lower, coletanea_names)\n",
    "    \n",
    "    for col_name, score in col_matches:\n",
    "        if score >= 0.7:\n",
    "            found_coletaneas.append(col_name)\n",
    "            # Remove a refer√™ncia da pergunta\n",
    "            question_lower = question_lower.replace(col_name.lower(), \" \")\n",
    "    \n",
    "    # Limpa a query removendo espa√ßos extras\n",
    "    cleaned_query = \" \".join(question_lower.split())\n",
    "    \n",
    "    return {\n",
    "        \"categorias\": found_categorias if found_categorias else None,\n",
    "        \"coletaneas\": found_coletaneas if found_coletaneas else None,\n",
    "        \"search_query\": cleaned_query if cleaned_query else question,\n",
    "        \"matches_info\": {\n",
    "            \"categorias_scores\": cat_matches[:3],\n",
    "            \"coletaneas_scores\": col_matches[:3],\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Sistema determin√≠stico de extra√ß√£o de filtros carregado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86176f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hybrid_retrieve_filtered_with_filters(search_query: str, filters: dict) -> list:\n",
    "    \"\"\"\n",
    "    Busca h√≠brida (vetorial + BM25) com filtros de categoria/colet√¢nea.\n",
    "    \n",
    "    Os filtros s√£o aplicados em l√≥gica de INTERSEC√á√ÉO (AND):\n",
    "    - Se h√° filtro de categoria, apenas hinos nessas categorias s√£o retornados\n",
    "    - Se h√° filtro de colet√¢nea, apenas hinos nessas colet√¢neas s√£o retornados\n",
    "    \"\"\"\n",
    "    # Coleta IDs de categorias/colet√¢neas\n",
    "    categoria_ids = []\n",
    "    if filters.get(\"categorias\"):\n",
    "        for cat_name in filters[\"categorias\"]:\n",
    "            cat_id = categorias.get(cat_name.lower())\n",
    "            if cat_id:\n",
    "                categoria_ids.append(cat_id)\n",
    "    \n",
    "    coletanea_ids = []\n",
    "    if filters.get(\"coletaneas\"):\n",
    "        for col_name in filters[\"coletaneas\"]:\n",
    "            col_id = coletaneas.get(col_name.lower())\n",
    "            if col_id:\n",
    "                coletanea_ids.append(col_id)\n",
    "    \n",
    "    if categoria_ids or coletanea_ids:\n",
    "        print(f\"üîç Filtros aplicados (INTERSEC√á√ÉO): categorias={categoria_ids}, coletaneas={coletanea_ids}\")\n",
    "    \n",
    "    # Helper para verificar se doc satisfaz os filtros (intersec√ß√£o/AND)\n",
    "    def matches_filters(doc) -> bool:\n",
    "        # Se temos filtro de categoria, doc deve estar em uma das categorias\n",
    "        if categoria_ids:\n",
    "            if doc.metadata.get(\"categoria_id\") not in categoria_ids:\n",
    "                return False\n",
    "        \n",
    "        # Se temos filtro de colet√¢nea, doc deve estar em uma das colet√¢neas\n",
    "        if coletanea_ids:\n",
    "            if doc.metadata.get(\"coletanea_id\") not in coletanea_ids:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # Busca vetorial\n",
    "    vec_docs = []\n",
    "    if categoria_ids or coletanea_ids:\n",
    "        # Estrat√©gia: fazer m√∫ltiplas buscas para cobrir todas as combina√ß√µes\n",
    "        seen_ids = set()\n",
    "        \n",
    "        if categoria_ids and coletanea_ids:\n",
    "            # Buscar todas as combina√ß√µes categoria x colet√¢nea\n",
    "            for cat_id in categoria_ids:\n",
    "                for col_id in coletanea_ids:\n",
    "                    try:\n",
    "                        docs = vectorstore.similarity_search(\n",
    "                            search_query, k=15, \n",
    "                            filter={\"categoria_id\": cat_id, \"coletanea_id\": col_id}\n",
    "                        )\n",
    "                        for doc in docs:\n",
    "                            hid = doc.metadata.get(\"hino_id\")\n",
    "                            if hid not in seen_ids:\n",
    "                                seen_ids.add(hid)\n",
    "                                vec_docs.append(doc)\n",
    "                    except:\n",
    "                        pass\n",
    "        elif categoria_ids:\n",
    "            # Apenas categorias: buscar com cada categoria\n",
    "            for cat_id in categoria_ids:\n",
    "                try:\n",
    "                    docs = vectorstore.similarity_search(\n",
    "                        search_query, k=15, filter={\"categoria_id\": cat_id}\n",
    "                    )\n",
    "                    for doc in docs:\n",
    "                        hid = doc.metadata.get(\"hino_id\")\n",
    "                        if hid not in seen_ids:\n",
    "                            seen_ids.add(hid)\n",
    "                            vec_docs.append(doc)\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            # Apenas colet√¢neas: buscar com cada colet√¢nea\n",
    "            for col_id in coletanea_ids:\n",
    "                try:\n",
    "                    docs = vectorstore.similarity_search(\n",
    "                        search_query, k=15, filter={\"coletanea_id\": col_id}\n",
    "                    )\n",
    "                    for doc in docs:\n",
    "                        hid = doc.metadata.get(\"hino_id\")\n",
    "                        if hid not in seen_ids:\n",
    "                            seen_ids.add(hid)\n",
    "                            vec_docs.append(doc)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Limita a 10 melhores (j√° ordenados por similaridade nas buscas individuais)\n",
    "        vec_docs = vec_docs[:10]\n",
    "        \n",
    "        # Se n√£o achou nada com filtros, busca sem filtros e filtra manualmente\n",
    "        if len(vec_docs) == 0:\n",
    "            all_docs = vector_retriever.invoke(search_query)\n",
    "            vec_docs = [d for d in all_docs if matches_filters(d)]\n",
    "    else:\n",
    "        vec_docs = vector_retriever.invoke(search_query)\n",
    "    \n",
    "    # BM25 com filtro manual (intersec√ß√£o)\n",
    "    if bm25_retriever:\n",
    "        bm25_docs = bm25_retriever.invoke(search_query)\n",
    "        if categoria_ids or coletanea_ids:\n",
    "            bm25_docs = [d for d in bm25_docs if matches_filters(d)]\n",
    "    else:\n",
    "        bm25_docs = []\n",
    "    \n",
    "    # Combina com deduplica√ß√£o\n",
    "    seen = set()\n",
    "    combined = []\n",
    "    for doc in vec_docs:\n",
    "        hid = doc.metadata.get('hino_id')\n",
    "        if hid not in seen:\n",
    "            seen.add(hid)\n",
    "            combined.append(doc)\n",
    "    \n",
    "    for doc in bm25_docs:\n",
    "        hid = doc.metadata.get('hino_id')\n",
    "        if hid not in seen and len(combined) < 10:\n",
    "            seen.add(hid)\n",
    "            combined.append(doc)\n",
    "    \n",
    "    return combined[:10]\n",
    "\n",
    "\n",
    "def answer_filtered(question: str, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Responde pergunta com extra√ß√£o determin√≠stica de filtros.\n",
    "    \"\"\"\n",
    "    bible_refs = extract_bible_refs(question)\n",
    "    bible_context = fetch_bible_verses(bible_refs) if bible_refs else \"\"\n",
    "    if verbose and bible_refs:\n",
    "        print(f\"üìñ Refer√™ncias b√≠blicas detectadas: {bible_refs}\")\n",
    "        if bible_context:\n",
    "            print(\"üì• Texto b√≠blico recuperado (resumo):\")\n",
    "            print(bible_context[:240] + (\"...\" if len(bible_context) > 240 else \"\"))\n",
    "\n",
    "    # Extra√ß√£o determin√≠stica de filtros\n",
    "    filters = _extract_filters_deterministic(question, categorias, coletaneas)\n",
    "    search_query = filters.get(\"search_query\", question)\n",
    "    \n",
    "    if verbose:\n",
    "        if filters.get(\"categorias\") or filters.get(\"coletaneas\"):\n",
    "            print(f\"üõ† Filtros detectados: categorias={filters.get('categorias')}, coletaneas={filters.get('coletaneas')}\")\n",
    "            print(f\"   (scores: {filters['matches_info']})\")\n",
    "        else:\n",
    "            print(f\"üõ† Sem filtros detectados\")\n",
    "        print(f\"üìù Query limpa: {search_query}\")\n",
    "\n",
    "    rewritten = rewrite_chain.invoke({\"question\": search_query})\n",
    "    if verbose:\n",
    "        print(f\"üìù Consulta reescrita: {rewritten}\")\n",
    "\n",
    "    effective_query = rewritten\n",
    "    if bible_context:\n",
    "        # Usa o texto b√≠blico para enriquecer a busca no vector/BM25\n",
    "        effective_query = rewritten + \"\\n\\n\" + '\"' + bible_context[:700] + '\"'\n",
    "        if verbose:\n",
    "            print(\"üîé Consulta efetiva enriquecida com texto b√≠blico\")\n",
    "\n",
    "    docs = hybrid_retrieve_filtered_with_filters(effective_query, filters)\n",
    "    if verbose:\n",
    "        print(f\"üìö Hinos encontrados: {len(docs)}\")\n",
    "        print(\"üîé Hinos selecionados:\")\n",
    "        for doc in docs:\n",
    "            print(f\"- [{doc.metadata.get('numero') or 'N/A'}] {doc.metadata.get('nome')}\")\n",
    "\n",
    "    if not docs:\n",
    "        return \"‚ùå Nenhum hino encontrado com esses crit√©rios.\"\n",
    "\n",
    "    context = format_docs(docs)\n",
    "    if bible_context:\n",
    "        context = context + \"\\n\\nTrechos b√≠blicos fornecidos:\\n\" + '\"' + bible_context + '\"'\n",
    "    filter_info = f\"\\nFiltros: {filters}\" if (filters.get(\"categorias\") or filters.get(\"coletaneas\")) else \"\"\n",
    "\n",
    "    final_prompt = answer_prompt.format(\n",
    "        question=question,\n",
    "        rewritten=rewritten + filter_info,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nüí¨ Gerando resposta...\")\n",
    "\n",
    "    return llm.invoke(final_prompt)\n",
    "\n",
    "print(\"‚úÖ Sistema de busca com filtros determin√≠sticos pronto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24140d03",
   "metadata": {},
   "source": [
    "## Exemplos de Uso\n",
    "\n",
    "Teste o sistema com diferentes consultas e filtros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ec4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Busca simples\n",
    "print(\"=\" * 60)\n",
    "print(\"EXEMPLO 1: Busca por tema\")\n",
    "print(\"=\" * 60)\n",
    "resposta = answer_filtered(\"Hinos que combinam com o texto de Isa√≠as 4:6\")\n",
    "print(f\"\\n{resposta}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Com filtro de categoria\n",
    "print(\"=\" * 60)\n",
    "print(\"EXEMPLO 2: Filtro de categoria\")\n",
    "print(\"=\" * 60)\n",
    "resposta = answer_filtered(\"Hinos da categoria de invoca√ß√£o e comunh√£o sobre unidade\")\n",
    "print(f\"\\n{resposta}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 3: Com filtro de colet√¢nea\n",
    "print(\"=\" * 60)\n",
    "print(\"EXEMPLO 3: Filtro de colet√¢nea\")\n",
    "print(\"=\" * 60)\n",
    "resposta = answer_filtered(\n",
    "    \"Hinos da colet√¢nea de louvores avulsos sobre Deus como uma \\\"torre forte\\\"\"\n",
    ")\n",
    "print(f\"\\n{resposta}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hinos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
